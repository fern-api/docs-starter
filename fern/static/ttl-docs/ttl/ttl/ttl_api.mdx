---
layout: overview
slug: ttl/ttl/ttl_api
title: ttl.ttl_api
---

Main API for the TTL dialect Python DSL.

## Module Contents

### Classes

| Name | Description |
|------|-------------|
| [`CompiledTTNNKernel`](#ttl-ttl_api-CompiledTTNNKernel) | A compiled tt-lang kernel ready for execution via ttnn.generic_op. |
| [`Program`](#ttl-ttl_api-Program) | Immutable container for kernel threads and their arguments. |

### Functions

| Name | Description |
|------|-------------|
| [`_clear_thread_registry`](#ttl-ttl_api-_clear_thread_registry) | Clear the thread registry before kernel execution. |
| [`_collect_captures`](#ttl-ttl_api-_collect_captures) | Collect and convert captured variables from function closure. |
| [`_collect_cb_configs`](#ttl-ttl_api-_collect_cb_configs) | Extract CircularBuffer objects from thread closures, indexed by cb_index. |
| [`_compile`](#ttl-ttl_api-_compile) | Internal decorator for compiling kernel threads. |
| [`_compile_kernel`](#ttl-ttl_api-_compile_kernel) | Compile kernel function to MLIR and return CompiledTTNNKernel. |
| [`_compile_ttnn_kernel`](#ttl-ttl_api-_compile_ttnn_kernel) | Compile kernel to CompiledTTNNKernel for execution via ttnn.generic_op. |
| [`_detect_memory_space_from_tensor`](#ttl-ttl_api-_detect_memory_space_from_tensor) | Detect memory space (L1/DRAM) from a ttnn tensor's buffer type. |
| [`_get_registered_threads`](#ttl-ttl_api-_get_registered_threads) | Get all registered threads and clear the registry. |
| [`_get_source_line_offset`](#ttl-ttl_api-_get_source_line_offset) | Get the line offset to convert parsed AST line numbers to actual file lines. |
| [`_get_tensor_cache_info`](#ttl-ttl_api-_get_tensor_cache_info) | Extract cache-relevant info from a tensor: (shape, dtype, memory_space, layout). |
| [`_has_float32_args`](#ttl-ttl_api-_has_float32_args) | Check if any input tensor uses float32 dtype. |
| [`_is_interleaved_tensor`](#ttl-ttl_api-_is_interleaved_tensor) | Check if a ttnn tensor has interleaved memory layout. |
| [`_make_cache_key`](#ttl-ttl_api-_make_cache_key) | Create cache key from tensor properties and runtime compute config parameters. |
| [`_register_thread`](#ttl-ttl_api-_register_thread) | Register a thread function during decoration. |
| [`_resolve_grid`](#ttl-ttl_api-_resolve_grid) | Resolve grid, evaluating callable or 'auto' if needed. |
| [`_run_profiling_pipeline`](#ttl-ttl_api-_run_profiling_pipeline) | Read device profiler data and display profile report. |
| [`_should_execute`](#ttl-ttl_api-_should_execute) | Check if kernel execution should proceed (not compile-only mode). |
| [`_track_tensor_sources`](#ttl-ttl_api-_track_tensor_sources) | Track source locations for tensor arguments. |
| [`_write_kernel_to_tmp`](#ttl-ttl_api-_write_kernel_to_tmp) | Write kernel source to /tmp and return the file path. |
| [`compute`](#ttl-ttl_api-compute) | Decorator for compute thread functions. |
| [`datamovement`](#ttl-ttl_api-datamovement) | Decorator for data movement thread functions. |
| [`pykernel_gen`](#ttl-ttl_api-pykernel_gen) | Decorator for generating TTL kernels from Python functions. |

### Data

[`__all__`](#ttl-ttl_api-__all__)

[`_thread_registry`](#ttl-ttl_api-_thread_registry)

[`kernel`](#ttl-ttl_api-kernel)

### API

<Anchor id="ttl-ttl_api-CompiledTTNNKernel">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
class ttl.ttl_api.CompiledTTNNKernel(
    kernel_paths,
    kernel_configs,
    kernel_arg_specs,
    num_tensors,
    core_ranges,
    kernel_tensor_indices,
    cb_configs = None,
    program_hash = None,
    source_lines = None,
    all_source_lines = None,
    thread_to_kernel = None,
    kernel_line_offsets = None
)
```

</CodeBlock>
</Anchor>

<Indent>

A compiled tt-lang kernel ready for execution via ttnn.generic_op.

Caches compilation artifacts (kernel paths, CB descriptors) so the kernel
can be executed multiple times with different tensors without recompiling.


<ParamField path="all_source_lines" type="= all_source_lines or &#123;&#125;">
</ParamField>

<ParamField path="cb_configs" type="= cb_configs or []">
</ParamField>

<ParamField path="kernel_line_offsets" type="= kernel_line_offsets or &#123;&#125;">
</ParamField>

<ParamField path="thread_to_kernel" type="= thread_to_kernel or &#123;&#125;">
</ParamField>
<Anchor id="ttl-ttl_api-CompiledTTNNKernel-__call__">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api.CompiledTTNNKernel.__call__(
    args = ()
)
```

</CodeBlock>
</Anchor>

<Indent>

Execute the kernel with the given tensors.


</Indent>
</Indent>

<Anchor id="ttl-ttl_api-Program">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
class ttl.ttl_api.Program(
    threads = (),
    args = (),
    kwargs = None
)
```

</CodeBlock>
</Anchor>

<Indent>

Immutable container for kernel threads and their arguments.

A Program encapsulates compute and data movement threads along with
the arguments to be passed during execution. After construction, all
fields should be treated as read-only.


<ParamField path="_kwargs" type="= kwargs if kwargs is not None else &#123;&#125;">
</ParamField>

<ParamField path="args" type="tuple">
</ParamField>

<ParamField path="kwargs" type="dict">
</ParamField>

<ParamField path="threads" type="tuple">
</ParamField>
<Anchor id="ttl-ttl_api-Program-__call__">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api.Program.__call__(
    args = (),
    kwargs = {}
)
```

</CodeBlock>
</Anchor>

<Indent>


</Indent>
</Indent>

<Anchor id="ttl-ttl_api-_clear_thread_registry">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._clear_thread_registry() -> None
```

</CodeBlock>
</Anchor>

<Indent>

Clear the thread registry before kernel execution.


</Indent>

<Anchor id="ttl-ttl_api-_collect_captures">

<CodeBlock links={{"ttl.circular_buffer.CircularBuffer":"/ttl/ttl/circular_buffer#ttl-circular_buffer-CircularBuffer"}} showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._collect_captures(
    f: typing.Callable
) -> typing.Dict[str, typing.Union[int, ttl.circular_buffer.CircularBuffer]]
```

</CodeBlock>
</Anchor>

<Indent>

Collect and convert captured variables from function closure.

**Parameters:**

<ParamField path="f" type="Callable">
Function with closure to inspect
</ParamField>

**Returns:** `Dict[str, Union[int, CircularBuffer]]`

Dictionary mapping variable names to converted values

**Raises:**

- `TypeError`: If closure contains unsupported variable types


</Indent>

<Anchor id="ttl-ttl_api-_collect_cb_configs">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._collect_cb_configs(
    threads
)
```

</CodeBlock>
</Anchor>

<Indent>

Extract CircularBuffer objects from thread closures, indexed by cb_index.

Returns a list of CircularBuffer objects indexed by cb_index. Each CB has
shape, buffer_factor, tensor (for dtype), and _cb_index attributes.


</Indent>

<Anchor id="ttl-ttl_api-_compile">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._compile(
    kernel_type: typing.Optional[str] = None,
    verbose: bool = False
) -> typing.Callable
```

</CodeBlock>
</Anchor>

<Indent>

Internal decorator for compiling kernel threads.

**Parameters:**

<ParamField path="kernel_type" type="Optional[str]" default="None">
Type of kernel ("compute" or "datamovement")
</ParamField>

<ParamField path="verbose" type="bool" default="False">
Enable verbose compilation output
</ParamField>

**Returns:** `Callable`

Decorator function for kernel compilation


</Indent>

<Anchor id="ttl-ttl_api-_compile_kernel">

<CodeBlock links={{"ttl.ttl_api.CompiledTTNNKernel":"#ttl-ttl_api-CompiledTTNNKernel"}} showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._compile_kernel(
    f: typing.Callable,
    args: tuple,
    kwargs: dict,
    grid: typing.Union[tuple, typing.List[int]],
    indexing_maps: typing.List[typing.Callable],
    iterator_types: typing.List[str],
    num_outs: int,
    memory_space: str,
    tiled: bool,
    program_hash: int,
    fp32_dest_acc_en: typing.Optional[bool] = None,
    dst_full_sync_en: typing.Optional[bool] = None
) -> typing.Optional[ttl.ttl_api.CompiledTTNNKernel]
```

</CodeBlock>
</Anchor>

<Indent>

Compile kernel function to MLIR and return CompiledTTNNKernel.

**Parameters:**

<ParamField path="f" type="Callable">
User kernel function
</ParamField>

<ParamField path="args" type="tuple">
Positional arguments for the kernel
</ParamField>

<ParamField path="kwargs" type="dict">
Keyword arguments for the kernel
</ParamField>

<ParamField path="grid" type="Union[tuple, List[int]]">
Grid dimensions
</ParamField>

<ParamField path="indexing_maps" type="List[Callable]">
List of lambda functions for indexing
</ParamField>

<ParamField path="iterator_types" type="List[str]">
List of iterator type strings
</ParamField>

<ParamField path="num_outs" type="int">
Number of output arguments
</ParamField>

<ParamField path="memory_space" type="str">
"L1" or "DRAM"
</ParamField>

<ParamField path="tiled" type="bool">
Whether to use tiled layout
</ParamField>

<ParamField path="program_hash" type="int">
Hash for tt-metal program cache
</ParamField>

<ParamField path="fp32_dest_acc_en" type="Optional[bool]" default="None">
Optional override for fp32_dest_acc_en
</ParamField>

<ParamField path="dst_full_sync_en" type="Optional[bool]" default="None">
Optional override for dst_full_sync_en
</ParamField>

**Returns:** `Optional[CompiledTTNNKernel]`

CompiledTTNNKernel ready for execution


</Indent>

<Anchor id="ttl-ttl_api-_compile_ttnn_kernel">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._compile_ttnn_kernel(
    module,
    args,
    grid,
    num_outs,
    thread_tensor_indices,
    cb_configs = None,
    program_hash = None,
    fp32_dest_acc_en: typing.Optional[bool] = None,
    dst_full_sync_en: typing.Optional[bool] = None,
    verbose = True,
    source_lines = None,
    all_source_lines = None,
    kernel_line_offsets = None
)
```

</CodeBlock>
</Anchor>

<Indent>

Compile kernel to CompiledTTNNKernel for execution via ttnn.generic_op.

Builds kernel paths, configs, and CB descriptors from compiled MLIR module.

**Parameters:**

<ParamField path="module">
MLIR module after D2M pipeline (with EmitC kernels)
</ParamField>

<ParamField path="args">
Input/output tensors (used for shape/dtype info)
</ParamField>

<ParamField path="grid">
Grid dimensions tuple
</ParamField>

<ParamField path="num_outs">
Number of output tensors
</ParamField>

<ParamField path="program_hash" default="None">
Hash for tt-metal program cache
</ParamField>

<ParamField path="verbose" default="True">
Print compilation info
</ParamField>

<ParamField path="source_lines" default="None">
Source code lines for auto-profiling reports
</ParamField>

**Returns:**

CompiledTTNNKernel ready for execution


</Indent>

<Anchor id="ttl-ttl_api-_detect_memory_space_from_tensor">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._detect_memory_space_from_tensor(
    tensor,
    default: str
) -> str
```

</CodeBlock>
</Anchor>

<Indent>

Detect memory space (L1/DRAM) from a ttnn tensor's buffer type.


</Indent>

<Anchor id="ttl-ttl_api-_get_registered_threads">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._get_registered_threads() -> typing.List[typing.Callable]
```

</CodeBlock>
</Anchor>

<Indent>

Get all registered threads and clear the registry.


</Indent>

<Anchor id="ttl-ttl_api-_get_source_line_offset">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._get_source_line_offset(
    f
) -> int
```

</CodeBlock>
</Anchor>

<Indent>

Get the line offset to convert parsed AST line numbers to actual file lines.


</Indent>

<Anchor id="ttl-ttl_api-_get_tensor_cache_info">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._get_tensor_cache_info(
    tensor
) -> tuple
```

</CodeBlock>
</Anchor>

<Indent>

Extract cache-relevant info from a tensor: (shape, dtype, memory_space, layout).


</Indent>

<Anchor id="ttl-ttl_api-_has_float32_args">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._has_float32_args(
    args
) -> bool
```

</CodeBlock>
</Anchor>

<Indent>

Check if any input tensor uses float32 dtype.

Inspects the tensor arguments to detect float32. This is used to
automatically enable fp32_dest_acc_en configuration for compute kernels.

**Parameters:**

<ParamField path="args">
List of tensor arguments (torch or ttnn)
</ParamField>

**Returns:** `bool`

True if any tensor uses float32 dtype, False otherwise


</Indent>

<Anchor id="ttl-ttl_api-_is_interleaved_tensor">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._is_interleaved_tensor(
    tensor
) -> bool
```

</CodeBlock>
</Anchor>

<Indent>

Check if a ttnn tensor has interleaved memory layout.


</Indent>

<Anchor id="ttl-ttl_api-_make_cache_key">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._make_cache_key(
    args: tuple,
    fp32_dest_acc_en: typing.Optional[bool],
    dst_full_sync_en: typing.Optional[bool]
) -> tuple
```

</CodeBlock>
</Anchor>

<Indent>

Create cache key from tensor properties and runtime compute config parameters.


</Indent>

<Anchor id="ttl-ttl_api-_register_thread">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._register_thread(
    thread_fn: typing.Callable
) -> None
```

</CodeBlock>
</Anchor>

<Indent>

Register a thread function during decoration.


</Indent>

<Anchor id="ttl-ttl_api-_resolve_grid">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._resolve_grid(
    grid,
    args,
    kwargs
)
```

</CodeBlock>
</Anchor>

<Indent>

Resolve grid, evaluating callable or 'auto' if needed.


</Indent>

<Anchor id="ttl-ttl_api-_run_profiling_pipeline">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._run_profiling_pipeline(
    tensors: tuple,
    all_source_lines: typing.Dict[str, typing.List[str]],
    thread_to_kernel: typing.Dict[str, str],
    kernel_line_offsets: typing.Optional[typing.Dict[str, int]] = None
)
```

</CodeBlock>
</Anchor>

<Indent>

Read device profiler data and display profile report.

Called after kernel execution when auto-profiling is enabled.

**Parameters:**

<ParamField path="tensors" type="tuple">
Tuple of tensor arguments passed to the kernel
</ParamField>

<ParamField path="all_source_lines" type="Dict[str, List[str]]">
Dict mapping kernel name to source lines
</ParamField>

<ParamField path="thread_to_kernel" type="Dict[str, str]">
Dict mapping RISC thread name to kernel name
</ParamField>


</Indent>

<Anchor id="ttl-ttl_api-_should_execute">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._should_execute() -> bool
```

</CodeBlock>
</Anchor>

<Indent>

Check if kernel execution should proceed (not compile-only mode).


</Indent>

<Anchor id="ttl-ttl_api-_track_tensor_sources">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._track_tensor_sources(
    f_params,
    args,
    source_file: str
) -> None
```

</CodeBlock>
</Anchor>

<Indent>

Track source locations for tensor arguments.

Searches backwards from the kernel call site to find where each
tensor variable was assigned, then registers that location.


</Indent>

<Anchor id="ttl-ttl_api-_write_kernel_to_tmp">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._write_kernel_to_tmp(
    name: str,
    source: str
) -> str
```

</CodeBlock>
</Anchor>

<Indent>

Write kernel source to /tmp and return the file path.


</Indent>

<Anchor id="ttl-ttl_api-compute">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api.compute(
    verbose: bool = False
) -> typing.Callable
```

</CodeBlock>
</Anchor>

<Indent>

Decorator for compute thread functions.

Compute threads execute on Tensix cores and perform mathematical operations.

**Parameters:**

<ParamField path="verbose" type="bool" default="False">
Enable verbose compilation output
</ParamField>

**Returns:** `Callable`

Decorator for compute kernel compilation


</Indent>

<Anchor id="ttl-ttl_api-datamovement">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api.datamovement(
    verbose: bool = False
) -> typing.Callable
```

</CodeBlock>
</Anchor>

<Indent>

Decorator for data movement thread functions.

Data movement threads handle DMA operations between memory hierarchies.

**Parameters:**

<ParamField path="verbose" type="bool" default="False">
Enable verbose compilation output
</ParamField>

**Returns:** `Callable`

Decorator for data movement kernel compilation


</Indent>

<Anchor id="ttl-ttl_api-pykernel_gen">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api.pykernel_gen(
    grid: typing.Optional[typing.Union[tuple, typing.Callable]] = None,
    indexing_maps: typing.Optional[typing.List[typing.Callable]] = None,
    iterator_types: typing.Optional[typing.List[str]] = None,
    num_outs: int = 1,
    memory_space: str = 'L1',
    tiled: bool = True,
    fp32_dest_acc_en: typing.Optional[bool] = None,
    dst_full_sync_en: typing.Optional[bool] = None
) -> typing.Callable
```

</CodeBlock>
</Anchor>

<Indent>

Decorator for generating TTL kernels from Python functions.

This decorator compiles Python functions into TTL dialect operations,
handling thread compilation, stream creation, and pipeline execution.
Kernels are compiled to C++ for execution via ttnn.generic_op.

**Parameters:**

<ParamField path="grid" type="Optional[Union[tuple, Callable]]" default="None">
Grid dimensions as tuple (e.g., (2, 2)) or callable
</ParamField>

<ParamField path="indexing_maps" type="Optional[List[Callable]]" default="None">
List of lambda functions for indexing (optional)
</ParamField>

<ParamField path="iterator_types" type="Optional[List[str]]" default="None">
List of iterator types ("parallel", "reduction")
</ParamField>

<ParamField path="num_outs" type="int" default="1">
Number of output arguments
</ParamField>

<ParamField path="memory_space" type="str" default="'L1'">
"L1" or "DRAM"
</ParamField>

<ParamField path="tiled" type="bool" default="True">
Whether to use tiled layout
</ParamField>

<ParamField path="fp32_dest_acc_en" type="Optional[bool]" default="None">
Optional override for fp32_dest_acc_en
</ParamField>

<ParamField path="dst_full_sync_en" type="Optional[bool]" default="None">
Optional override for dst_full_sync_en
</ParamField>

**Returns:** `Callable`

Decorated function that compiles and executes the kernel

**Raises:**

- `AssertionError`: If required parameters are missing or invalid


</Indent>

<Anchor id="ttl-ttl_api-__all__">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api.__all__ = ['pykernel_gen', 'kernel', 'Program', 'compute', 'datamovement', 'TensorBlock', ...
```

</CodeBlock>
</Anchor>


<Anchor id="ttl-ttl_api-_thread_registry">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api._thread_registry: List[Callable] = []
```

</CodeBlock>
</Anchor>


<Anchor id="ttl-ttl_api-kernel">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
ttl.ttl_api.kernel = pykernel_gen
```

</CodeBlock>
</Anchor>

