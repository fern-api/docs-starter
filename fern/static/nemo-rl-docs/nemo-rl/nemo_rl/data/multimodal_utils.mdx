---
layout: overview
slug: nemo-rl/nemo_rl/data/multimodal_utils
title: nemo_rl.data.multimodal_utils
---

## Module Contents

### Classes

| Name | Description |
|------|-------------|
| [`PackedTensor`](#nemo_rl-data-multimodal_utils-PackedTensor) | Wrapper around a list of torch tensors and a dimension along which to pack the tensors. |

### Functions

| Name | Description |
|------|-------------|
| [`get_dim_to_pack_along`](#nemo_rl-data-multimodal_utils-get_dim_to_pack_along) | Special considerations for packing certain keys from certain processors. |
| [`get_multimodal_keys_from_processor`](#nemo_rl-data-multimodal_utils-get_multimodal_keys_from_processor) | Get keys of the multimodal data that can be used as model inputs. |
| [`resolve_to_image`](#nemo_rl-data-multimodal_utils-resolve_to_image) | Resolve the image path to a PIL.Image object. |

### API

<Anchor id="nemo_rl-data-multimodal_utils-PackedTensor">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
class nemo_rl.data.multimodal_utils.PackedTensor(
    tensors: typing.Union[torch.Tensor, list[typing.Optional[torch.Tensor]], list[None]],
    dim_to_pack: int
)
```

</CodeBlock>
</Anchor>

<Indent>

Wrapper around a list of torch tensors and a dimension along which to pack the tensors.

This class is used to wrap a list of tensors along with a `dim_to_pack` parameter.
It can be used for data that can be packed along different dimensions (such as multimodal data).

`dim_to_pack` is used to specify the dimension along which to pack the tensors.

The list of tensors can be returned as a single packed tensor by calling `as_tensor` which will concatenate the tensors along the `dim_to_pack` dimension.


<ParamField path="tensors" type="list[Optional[Tensor]] = [tensors]">
</ParamField>
<Anchor id="nemo_rl-data-multimodal_utils-PackedTensor-__len__">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.multimodal_utils.PackedTensor.__len__() -> int
```

</CodeBlock>
</Anchor>

<Indent>


</Indent>
<Anchor id="nemo_rl-data-multimodal_utils-PackedTensor-as_tensor">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.multimodal_utils.PackedTensor.as_tensor(
    device: typing.Optional[torch.device] = None
) -> typing.Optional[torch.Tensor]
```

</CodeBlock>
</Anchor>

<Indent>


</Indent>
<Anchor id="nemo_rl-data-multimodal_utils-PackedTensor-concat">

<CodeBlock links={{"nemo_rl.data.multimodal_utils.PackedTensor":"#nemo_rl-data-multimodal_utils-PackedTensor"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.multimodal_utils.PackedTensor.concat(
    from_packed_tensors: list[nemo_rl.data.multimodal_utils.PackedTensor]
) -> nemo_rl.data.multimodal_utils.PackedTensor
```

</CodeBlock>
</Anchor>

<Indent>

<Badge>classmethod</Badge>

Concatenate a list of PackedTensor objects into a single PackedTensor.

The underlying tensors from the PackedTensors are combined into a single list of tensors and used to create a new PackedTensor.

Each batch must have the same dim_to_pack.

Example:
<CodeBlock showLineNumbers={false}>

```python
>>> import torch
>>> from nemo_rl.data.multimodal_utils import PackedTensor
>>> p1 = PackedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5, 6])], dim_to_pack=0)
>>> p2 = PackedTensor([torch.tensor([7, 8, 9])], dim_to_pack=0)
>>> p3 = PackedTensor.concat([p1, p2])
>>> p3.tensors
[tensor([1, 2, 3]), tensor([4, 5, 6]), tensor([7, 8, 9])]
>>> p3.as_tensor()
tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])
>>>
```

</CodeBlock>


</Indent>
<Anchor id="nemo_rl-data-multimodal_utils-PackedTensor-empty_like">

<CodeBlock links={{"nemo_rl.data.multimodal_utils.PackedTensor":"#nemo_rl-data-multimodal_utils-PackedTensor"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.multimodal_utils.PackedTensor.empty_like(
    other: nemo_rl.data.multimodal_utils.PackedTensor
) -> nemo_rl.data.multimodal_utils.PackedTensor
```

</CodeBlock>
</Anchor>

<Indent>

<Badge>classmethod</Badge>

Return a new PackedTensor with same length and dim_to_pack as `other`, with all entries None.


</Indent>
<Anchor id="nemo_rl-data-multimodal_utils-PackedTensor-flattened_concat">

<CodeBlock links={{"nemo_rl.data.multimodal_utils.PackedTensor":"#nemo_rl-data-multimodal_utils-PackedTensor"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.multimodal_utils.PackedTensor.flattened_concat(
    from_packed_tensors: list[nemo_rl.data.multimodal_utils.PackedTensor]
) -> nemo_rl.data.multimodal_utils.PackedTensor
```

</CodeBlock>
</Anchor>

<Indent>

<Badge>classmethod</Badge>

Given a list of PackedTensor objects, flattens each PackedTensor and then concatenates them into a single PackedTensor.

Each PackedTensor is first flattened by packing along the PackedTensor's `dim_to_pack` dimension. Then, the resulting flattened tensors are used to create a new PackedTensor.

This is different from `PackedTensor.concat` which simply extends the underlying list of tensors. This is important because the `slice` and `__len__` methods operate on the underlying list of tensors. Note, however, that calling `as_tensor` on the resulting PackedTensor will result in the same tensor as `concat`.

Each batch must have the same dim_to_pack.

Example:
<CodeBlock showLineNumbers={false}>

```python
>>> import torch
>>> from nemo_rl.data.multimodal_utils import PackedTensor
>>> p1 = PackedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5, 6])], dim_to_pack=0)
>>> p2 = PackedTensor([torch.tensor([7, 8, 9])], dim_to_pack=0)
>>> p3 = PackedTensor.flattened_concat([p1, p2])
>>> p3.tensors
[tensor([1, 2, 3, 4, 5, 6]), tensor([7, 8, 9])]
>>> p3.as_tensor()
tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])
>>>
```

</CodeBlock>


</Indent>
<Anchor id="nemo_rl-data-multimodal_utils-PackedTensor-slice">

<CodeBlock links={{"nemo_rl.data.multimodal_utils.PackedTensor":"#nemo_rl-data-multimodal_utils-PackedTensor"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.multimodal_utils.PackedTensor.slice(
    indices: typing.Union[list[int], torch.Tensor]
) -> nemo_rl.data.multimodal_utils.PackedTensor
```

</CodeBlock>
</Anchor>

<Indent>


</Indent>
<Anchor id="nemo_rl-data-multimodal_utils-PackedTensor-to">

<CodeBlock links={{"nemo_rl.data.multimodal_utils.PackedTensor":"#nemo_rl-data-multimodal_utils-PackedTensor"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.multimodal_utils.PackedTensor.to(
    device: str | torch.device
) -> nemo_rl.data.multimodal_utils.PackedTensor
```

</CodeBlock>
</Anchor>

<Indent>


</Indent>
</Indent>

<Anchor id="nemo_rl-data-multimodal_utils-get_dim_to_pack_along">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.multimodal_utils.get_dim_to_pack_along(
    processor,
    key: str
) -> int
```

</CodeBlock>
</Anchor>

<Indent>

Special considerations for packing certain keys from certain processors.

In most cases, the packed items are along dim 0


</Indent>

<Anchor id="nemo_rl-data-multimodal_utils-get_multimodal_keys_from_processor">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.multimodal_utils.get_multimodal_keys_from_processor(
    processor
) -> list[str]
```

</CodeBlock>
</Anchor>

<Indent>

Get keys of the multimodal data that can be used as model inputs.

This will be used in the data_processor function to determine which keys to use as model inputs.


</Indent>

<Anchor id="nemo_rl-data-multimodal_utils-resolve_to_image">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.multimodal_utils.resolve_to_image(
    image_path_or_image: str | PIL.Image.Image
) -> PIL.Image.Image
```

</CodeBlock>
</Anchor>

<Indent>

Resolve the image path to a PIL.Image object.

image_path can be either:
- path to local file
- url to image
- base64 encoded image


</Indent>
