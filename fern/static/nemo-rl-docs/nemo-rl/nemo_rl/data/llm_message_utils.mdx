---
layout: overview
slug: nemo-rl/nemo_rl/data/llm_message_utils
title: nemo_rl.data.llm_message_utils
---

## Module Contents

### Functions

| Name | Description |
|------|-------------|
| [`_pad_tensor`](#nemo_rl-data-llm_message_utils-_pad_tensor) | Pad a tensor to the specified length. |
| [`_validate_tensor_consistency`](#nemo_rl-data-llm_message_utils-_validate_tensor_consistency) | Validate that all tensors have consistent dtypes and devices. |
| [`add_loss_mask_to_message_log`](#nemo_rl-data-llm_message_utils-add_loss_mask_to_message_log) | Add token-level loss masks to each message in a message log. |
| [`batched_message_log_to_flat_message`](#nemo_rl-data-llm_message_utils-batched_message_log_to_flat_message) | Process and pad a batch of message logs for model input. |
| [`get_first_index_that_differs`](#nemo_rl-data-llm_message_utils-get_first_index_that_differs) | Get the first index that differs between two strings. |
| [`get_formatted_message_log`](#nemo_rl-data-llm_message_utils-get_formatted_message_log) | Format and tokenize chat messages using the specified template. |
| [`get_images_from_message`](#nemo_rl-data-llm_message_utils-get_images_from_message) | Get all images from a message log item. |
| [`get_keys_from_message_log`](#nemo_rl-data-llm_message_utils-get_keys_from_message_log) | Return a new LLMMessageLogType containing only the specified keys from each message. |
| [`message_log_shape`](#nemo_rl-data-llm_message_utils-message_log_shape) | Get the shape of the tensors in the message log. |
| [`message_log_to_flat_messages`](#nemo_rl-data-llm_message_utils-message_log_to_flat_messages) | Converts a message log (sequence of message turns) into a flattened representation. |
| [`remap_dataset_keys`](#nemo_rl-data-llm_message_utils-remap_dataset_keys) | Remap dataset keys as per mapping. |

### Data

[`Tensor`](#nemo_rl-data-llm_message_utils-Tensor)

[`TokenizerType`](#nemo_rl-data-llm_message_utils-TokenizerType)

### API

<Anchor id="nemo_rl-data-llm_message_utils-_pad_tensor">

<CodeBlock links={{"nemo_rl.data.llm_message_utils.Tensor":"#nemo_rl-data-llm_message_utils-Tensor"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.llm_message_utils._pad_tensor(
    tensor: nemo_rl.data.llm_message_utils.Tensor,
    max_len: int,
    pad_side: str,
    pad_value: int = 0
) -> nemo_rl.data.llm_message_utils.Tensor
```

</CodeBlock>
</Anchor>

<Indent>

Pad a tensor to the specified length.

**Parameters:**

<ParamField path="tensor" type="Tensor">
Tensor to pad
</ParamField>

<ParamField path="max_len" type="int">
Length to pad to
</ParamField>

<ParamField path="pad_side" type="str">
Whether to pad on the 'left' or 'right'
</ParamField>

<ParamField path="pad_value" type="int" default="0">
Value to use for padding
</ParamField>

**Returns:** `Tensor`

torch.Tensor: Padded tensor


</Indent>

<Anchor id="nemo_rl-data-llm_message_utils-_validate_tensor_consistency">

<CodeBlock links={{"nemo_rl.data.llm_message_utils.Tensor":"#nemo_rl-data-llm_message_utils-Tensor"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.llm_message_utils._validate_tensor_consistency(
    tensors: list[nemo_rl.data.llm_message_utils.Tensor]
) -> None
```

</CodeBlock>
</Anchor>

<Indent>

Validate that all tensors have consistent dtypes and devices.

**Parameters:**

<ParamField path="tensors" type="list[Tensor]">
List of tensors to validate
</ParamField>

**Raises:**

- `RuntimeError`: If tensors have different dtypes or devices


</Indent>

<Anchor id="nemo_rl-data-llm_message_utils-add_loss_mask_to_message_log">

<CodeBlock links={{"nemo_rl.data.interfaces.LLMMessageLogType":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-LLMMessageLogType"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.llm_message_utils.add_loss_mask_to_message_log(
    batch_message_log: list[nemo_rl.data.interfaces.LLMMessageLogType],
    roles_to_train_on: list[str] = ['assistant'],
    only_unmask_final: bool = False
) -> None
```

</CodeBlock>
</Anchor>

<Indent>

Add token-level loss masks to each message in a message log.

**Parameters:**

<ParamField path="message_log" type="LLMMessageLogType">
List of message dictionaries containing token IDs and metadata
</ParamField>

<ParamField path="roles_to_train_on" type="list[str]" default="['assistant']">
List of strings indicating which speakers to unmask. Default: ["assistant"]
</ParamField>

<ParamField path="only_unmask_final" type="bool" default="False">
If True, only unmask the final message in the log. Default: False
</ParamField>


</Indent>

<Anchor id="nemo_rl-data-llm_message_utils-batched_message_log_to_flat_message">

<CodeBlock links={{"nemo_rl.data.interfaces.LLMMessageLogType":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-LLMMessageLogType","nemo_rl.distributed.batched_data_dict.BatchedDataDict":"/nemo-rl/nemo_rl/distributed/batched_data_dict#nemo_rl-distributed-batched_data_dict-BatchedDataDict","nemo_rl.data.interfaces.FlatMessagesType":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-FlatMessagesType","nemo_rl.data.llm_message_utils.Tensor":"#nemo_rl-data-llm_message_utils-Tensor"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.llm_message_utils.batched_message_log_to_flat_message(
    message_log_batch: list[nemo_rl.data.interfaces.LLMMessageLogType],
    pad_value_dict: typing.Optional[dict[str, int]] = None,
    make_sequence_length_divisible_by: int = 1
) -> tuple[nemo_rl.distributed.batched_data_dict.BatchedDataDict[nemo_rl.data.interfaces.FlatMessagesType], nemo_rl.data.llm_message_utils.Tensor]
```

</CodeBlock>
</Anchor>

<Indent>

Process and pad a batch of message logs for model input.

For each message log in the batch:
1. Converts it to a flat representation using message_log_to_flat_messages
2. Pads all resulting tensors to the same length for batching
3. Returns a BatchedDataDict and sequence lengths tensor

Padding is always applied to the right side of sequences.

Examples:
<CodeBlock showLineNumbers={false}>

```python
>>> import torch
>>> from nemo_rl.data.llm_message_utils import batched_message_log_to_flat_message
>>> from nemo_rl.distributed.batched_data_dict import BatchedDataDict
>>> # Create a batch of two message logs with different lengths
>>> message_log_batch = [
...     # First conversation
...     [
...         {'role': 'user', 'content': 'What is 2+2?', 'token_ids': torch.tensor([1, 2, 3, 4, 5])},
...         {'role': 'assistant', 'content': '4', 'token_ids': torch.tensor([6, 7])}
...     ],
...     # Second conversation
...     [
...         {'role': 'user', 'content': 'Solve x+10=15', 'token_ids': torch.tensor([1, 8, 9, 10, 11, 12])},
...         {'role': 'assistant', 'content': 'x=5', 'token_ids': torch.tensor([13, 14, 15])}
...     ]
... ]
>>> pad_value_dict = {'token_ids': 0}
>>> batched_flat, input_lengths = batched_message_log_to_flat_message(message_log_batch, pad_value_dict)
>>> batched_flat['token_ids'][0].tolist()
[1, 2, 3, 4, 5, 6, 7, 0, 0]
>>> batched_flat['token_ids'][1].tolist()
[1, 8, 9, 10, 11, 12, 13, 14, 15]
>>> batched_flat['content'][0]
['What is 2+2?', '4']
>>> batched_flat['content'][1]
['Solve x+10=15', 'x=5']
>>> batched_flat['role']
[['user', 'assistant'], ['user', 'assistant']]
>>> input_lengths
tensor([7, 9], dtype=torch.int32)
>>>
>>> # Multimodal example: include images on both conversations and verify packing
>>> from nemo_rl.data.multimodal_utils import PackedTensor
>>> mm_batch = [
...     [
...         {'role': 'user', 'content': 'look', 'token_ids': torch.tensor([1, 2, 3]), 'images': PackedTensor(torch.randn(2, 3, 4, 4), dim_to_pack=0)},
...         {'role': 'assistant', 'content': 'ok', 'token_ids': torch.tensor([4])}
...     ],
...     [
...         {'role': 'user', 'content': 'again', 'token_ids': torch.tensor([5, 6]), 'images': PackedTensor(torch.randn(1, 3, 4, 4), dim_to_pack=0)},
...         {'role': 'assistant', 'content': 'fine', 'token_ids': torch.tensor([7, 8])}
...     ]
... ]
>>> mm_flat, mm_lengths = batched_message_log_to_flat_message(mm_batch, pad_value_dict={'token_ids': 0})
>>> isinstance(mm_flat['images'], PackedTensor)
True
>>> tuple(mm_flat['images'].as_tensor().shape)  # 2 + 1 images
(3, 3, 4, 4)
>>> mm_lengths
tensor([4, 4], dtype=torch.int32)
>>>
```

</CodeBlock>

**Parameters:**

<ParamField path="message_log_batch" type="list[LLMMessageLogType]">
List of LLMMessageLogType (each a conversation with multiple turns)
</ParamField>

<ParamField path="pad_value_dict" type="Optional[dict[str, int]]" default="None">
Dictionary mapping keys to padding values (default is 0)
</ParamField>

<ParamField path="make_sequence_length_divisible_by" type="int" default="1">
forces the data to be divisible by this value
</ParamField>

**Returns:** `BatchedDataDict[FlatMessagesType]`

BatchedDataDict[FlatMessagesType]: Dictionary containing padded stacked tensors

**Raises:**

- `RuntimeError`: If tensors have different dtypes or devices


</Indent>

<Anchor id="nemo_rl-data-llm_message_utils-get_first_index_that_differs">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.llm_message_utils.get_first_index_that_differs(
    str1: str,
    str2: str
) -> int
```

</CodeBlock>
</Anchor>

<Indent>

Get the first index that differs between two strings.


</Indent>

<Anchor id="nemo_rl-data-llm_message_utils-get_formatted_message_log">

<CodeBlock links={{"nemo_rl.data.interfaces.LLMMessageLogType":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-LLMMessageLogType","nemo_rl.data.llm_message_utils.TokenizerType":"#nemo_rl-data-llm_message_utils-TokenizerType","nemo_rl.data.interfaces.TaskDataSpec":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-TaskDataSpec"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.llm_message_utils.get_formatted_message_log(
    message_log: nemo_rl.data.interfaces.LLMMessageLogType,
    tokenizer: nemo_rl.data.llm_message_utils.TokenizerType,
    task_data_spec: nemo_rl.data.interfaces.TaskDataSpec,
    add_bos_token: bool = True,
    add_eos_token: bool = True,
    add_generation_prompt: bool = False,
    tools: typing.Optional[list[dict[str, typing.Any]]] = None
) -> nemo_rl.data.interfaces.LLMMessageLogType
```

</CodeBlock>
</Anchor>

<Indent>

Format and tokenize chat messages using the specified template.

Returns:
    The message log with updated 'token_ids' and 'content' fields.

**Parameters:**

<ParamField path="message_log" type="LLMMessageLogType">
List of message dicts with 'role' and 'content' keys
</ParamField>

<ParamField path="tokenizer" type="TokenizerType">
Tokenizer for converting text to token IDs
</ParamField>

<ParamField path="task_data_spec" type="TaskDataSpec">
Task spec for this dataset.
</ParamField>

<ParamField path="add_bos_token" type="bool" default="True">
Whether to add bos token to first message if it is not already present. Default: True
</ParamField>

<ParamField path="add_eos_token" type="bool" default="True">
Whether to add eos token to last message if it is not already present. Default: True
</ParamField>

<ParamField path="add_generation_prompt" type="bool" default="False">
Whether to include assistant's generation prompt in user messages. Default: False
</ParamField>

<ParamField path="tools" type="Optional[list[dict[str, Any]]]" default="None">
Optional list of tool/function definitions to pass to the chat template. Default: None
</ParamField>


</Indent>

<Anchor id="nemo_rl-data-llm_message_utils-get_images_from_message">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.llm_message_utils.get_images_from_message(
    message: dict[str, typing.Any]
) -> list[typing.Any]
```

</CodeBlock>
</Anchor>

<Indent>

Get all images from a message log item.


</Indent>

<Anchor id="nemo_rl-data-llm_message_utils-get_keys_from_message_log">

<CodeBlock links={{"nemo_rl.data.interfaces.LLMMessageLogType":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-LLMMessageLogType"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.llm_message_utils.get_keys_from_message_log(
    message_log: nemo_rl.data.interfaces.LLMMessageLogType,
    keys: list[str]
) -> nemo_rl.data.interfaces.LLMMessageLogType
```

</CodeBlock>
</Anchor>

<Indent>

Return a new LLMMessageLogType containing only the specified keys from each message.

**Parameters:**

<ParamField path="message_log" type="LLMMessageLogType">
Original message log to extract keys from
</ParamField>

<ParamField path="keys" type="list[str]">
List of keys to keep in each message
</ParamField>

**Returns:** `LLMMessageLogType`

New list with only specified keys


</Indent>

<Anchor id="nemo_rl-data-llm_message_utils-message_log_shape">

<CodeBlock links={{"nemo_rl.data.interfaces.LLMMessageLogType":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-LLMMessageLogType"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.llm_message_utils.message_log_shape(
    message_log: nemo_rl.data.interfaces.LLMMessageLogType
) -> list[dict[str, torch.Size]]
```

</CodeBlock>
</Anchor>

<Indent>

Get the shape of the tensors in the message log.

This utility function examines each message in the message log and reports
the shape of tensor values or recursively processes list values.

**Parameters:**

<ParamField path="message_log" type="LLMMessageLogType">
The message log to analyze
</ParamField>

**Returns:** `list[dict[str, torch.Size]]`

List of dictionaries containing tensor shapes for each key in messages


</Indent>

<Anchor id="nemo_rl-data-llm_message_utils-message_log_to_flat_messages">

<CodeBlock links={{"nemo_rl.data.interfaces.LLMMessageLogType":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-LLMMessageLogType","nemo_rl.data.interfaces.FlatMessagesType":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-FlatMessagesType"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.llm_message_utils.message_log_to_flat_messages(
    message_log: nemo_rl.data.interfaces.LLMMessageLogType
) -> nemo_rl.data.interfaces.FlatMessagesType
```

</CodeBlock>
</Anchor>

<Indent>

Converts a message log (sequence of message turns) into a flattened representation.

This function takes a message log (list of dict messages with 'role', 'content', 'token_ids', etc.)
and converts it to a flat dictionary where all tensors of the same key are concatenated and
all strings of the same key are put into lists.

Examples:
<CodeBlock showLineNumbers={false}>

```python
>>> import torch
>>> from nemo_rl.data.llm_message_utils import message_log_to_flat_messages
>>> # Create a simple message log with two messages
>>> message_log = [
...     {'role': 'user', 'content': 'Hello', 'token_ids': torch.tensor([1, 2, 3])},
...     {'role': 'assistant', 'content': 'Hi there', 'token_ids': torch.tensor([4, 5, 6, 7])}
... ]
>>> flat_msgs = message_log_to_flat_messages(message_log)
>>> flat_msgs['role']
['user', 'assistant']
>>> flat_msgs['content']
['Hello', 'Hi there']
>>> flat_msgs['token_ids']
tensor([1, 2, 3, 4, 5, 6, 7])
>>>
>>> # Multimodal example:
>>> from nemo_rl.data.multimodal_utils import PackedTensor
>>> img1 = torch.randn(2, 3, 4, 4)
>>> img2 = torch.randn(3, 3, 4, 4)
>>> mm_log = [
...     {'role': 'user', 'content': 'see', 'token_ids': torch.tensor([1]), 'images': PackedTensor(img1, dim_to_pack=0)},
...     {'role': 'assistant', 'content': 'ok', 'token_ids': torch.tensor([2, 3]), 'images': PackedTensor(img2, dim_to_pack=0)},
... ]
>>> flat_mm = message_log_to_flat_messages(mm_log)
>>> tuple(flat_mm['images'].as_tensor().shape)
(5, 3, 4, 4)
>>>
```

</CodeBlock>

**Parameters:**

<ParamField path="message_log" type="LLMMessageLogType">
List of message dictionaries with 'role', 'content', and potentially 'token_ids'
</ParamField>

**Returns:** `FlatMessagesType`

Dictionary mapping keys to concatenated tensors and string lists


</Indent>

<Anchor id="nemo_rl-data-llm_message_utils-remap_dataset_keys">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.llm_message_utils.remap_dataset_keys(
    dataset: datasets.Dataset,
    mapping_dict: dict[str, str]
) -> datasets.Dataset
```

</CodeBlock>
</Anchor>

<Indent>

Remap dataset keys as per mapping.

**Parameters:**

<ParamField path="dataset" type="Dataset">
The input dataset to remap keys in
</ParamField>

<ParamField path="mapping_dict" type="dict[str, str]">
A dictionary mapping input keys to output keys
</ParamField>

**Returns:** `Dataset`

A new dataset with remapped keys


</Indent>

<Anchor id="nemo_rl-data-llm_message_utils-Tensor">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.llm_message_utils.Tensor = torch.Tensor
```

</CodeBlock>
</Anchor>


<Anchor id="nemo_rl-data-llm_message_utils-TokenizerType">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.llm_message_utils.TokenizerType = PreTrainedTokenizerBase
```

</CodeBlock>
</Anchor>

