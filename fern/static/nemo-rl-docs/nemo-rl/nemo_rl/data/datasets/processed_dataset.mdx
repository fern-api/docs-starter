---
layout: overview
slug: nemo-rl/nemo_rl/data/datasets/processed_dataset
title: nemo_rl.data.datasets.processed_dataset
---

## Module Contents

### Classes

| Name | Description |
|------|-------------|
| [`AllTaskProcessedDataset`](#nemo_rl-data-datasets-processed_dataset-AllTaskProcessedDataset) | Dataset for processing single or multi-task data with task-specific tokenization and processing. |

### Data

[`TokenizerType`](#nemo_rl-data-datasets-processed_dataset-TokenizerType)

### API

<Anchor id="nemo_rl-data-datasets-processed_dataset-AllTaskProcessedDataset">

<CodeBlock links={{"nemo_rl.data.datasets.processed_dataset.TokenizerType":"#nemo_rl-data-datasets-processed_dataset-TokenizerType","nemo_rl.data.interfaces.TaskDataSpec":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-TaskDataSpec","nemo_rl.data.interfaces.TaskDataProcessFnCallable":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-TaskDataProcessFnCallable"}} showLineNumbers={false} wordWrap={true}>

```python
class nemo_rl.data.datasets.processed_dataset.AllTaskProcessedDataset(
    dataset: datasets.Dataset | typing.Any,
    tokenizer: nemo_rl.data.datasets.processed_dataset.TokenizerType,
    default_task_data_spec: nemo_rl.data.interfaces.TaskDataSpec,
    task_data_processors: dict[str, tuple[nemo_rl.data.interfaces.TaskDataSpec, nemo_rl.data.interfaces.TaskDataProcessFnCallable]] | nemo_rl.data.interfaces.TaskDataProcessFnCallable,
    max_seq_length: typing.Optional[int] = None
)
```

</CodeBlock>
</Anchor>

<Indent>

Dataset for processing single or multi-task data with task-specific tokenization and processing.

**Parameters:**

<ParamField path="dataset" type="Dataset | Any">
Input dataset containing raw data
</ParamField>

<ParamField path="tokenizer" type="TokenizerType">
Tokenizer for text processing
</ParamField>

<ParamField path="default_task_data_spec" type="TaskDataSpec">
Default task processing specifications.
In the case of single-task, this is the spec used for processing all entries.
In the case of multi-task, any values not specified in the task-specific specs will be taken from the default spec.
</ParamField>

<ParamField path="task_data_processors" type="dict[str, tuple[TaskDataSpec, TaskDataProcessFnCallable]] | TaskDataProcessFnCallable">
Either a single TaskDataProcessFnCallable for single-task,
or a dict mapping task names to (TaskDataSpec, TaskDataProcessFnCallable) for multi-task
</ParamField>

<ParamField path="max_seq_length" type="Optional[int]" default="None">
Maximum sequence length for tokenized outputs
</ParamField>


<Anchor id="nemo_rl-data-datasets-processed_dataset-AllTaskProcessedDataset-__getitem__">

<CodeBlock links={{"nemo_rl.data.interfaces.DatumSpec":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-DatumSpec"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.datasets.processed_dataset.AllTaskProcessedDataset.__getitem__(
    idx: int
) -> nemo_rl.data.interfaces.DatumSpec
```

</CodeBlock>
</Anchor>

<Indent>

Return a single prompt.


</Indent>
<Anchor id="nemo_rl-data-datasets-processed_dataset-AllTaskProcessedDataset-__len__">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.datasets.processed_dataset.AllTaskProcessedDataset.__len__() -> int
```

</CodeBlock>
</Anchor>

<Indent>


</Indent>
<Anchor id="nemo_rl-data-datasets-processed_dataset-AllTaskProcessedDataset-encode_single">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.datasets.processed_dataset.AllTaskProcessedDataset.encode_single(
    text: typing.Union[str, list[str]]
) -> tuple[list[int] | torch.Tensor, int]
```

</CodeBlock>
</Anchor>

<Indent>

Takes either a single string or a list of strings that represent multiple turns for the same conversation.

Returns a single (concatenated) list of tokenized ids and the length of the tokenized ids.


</Indent>
</Indent>

<Anchor id="nemo_rl-data-datasets-processed_dataset-TokenizerType">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.data.datasets.processed_dataset.TokenizerType = Union[PreTrainedTokenizerBase, AutoProcessor]
```

</CodeBlock>
</Anchor>

