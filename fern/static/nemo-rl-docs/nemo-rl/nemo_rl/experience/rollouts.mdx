---
layout: overview
slug: nemo-rl/nemo_rl/experience/rollouts
title: nemo_rl.experience.rollouts
---

## Module Contents

### Classes

| Name | Description |
|------|-------------|
| [`AsyncNemoGymRolloutResult`](#nemo_rl-experience-rollouts-AsyncNemoGymRolloutResult) | - |

### Functions

| Name | Description |
|------|-------------|
| [`_calculate_single_metric`](#nemo_rl-experience-rollouts-_calculate_single_metric) | - |
| [`async_generate_response_for_sample_turn`](#nemo_rl-experience-rollouts-async_generate_response_for_sample_turn) | Generate a response for a single sample's turn using async generation. |
| [`calculate_rewards`](#nemo_rl-experience-rollouts-calculate_rewards) | Calculate rewards for generated responses and get environment feedback. |
| [`generate_responses`](#nemo_rl-experience-rollouts-generate_responses) | Generate responses from policy using synchronous generation. |
| [`generate_responses_async`](#nemo_rl-experience-rollouts-generate_responses_async) | Async version of generate_responses that properly calls generate_async. |
| [`run_async_multi_turn_rollout`](#nemo_rl-experience-rollouts-run_async_multi_turn_rollout) | Run multi-turn rollouts with sample-level processing. |
| [`run_async_nemo_gym_rollout`](#nemo_rl-experience-rollouts-run_async_nemo_gym_rollout) | Run multi-turn rollouts with NeMo-Gym. Please refer to the `run_async_multi_turn_rollout` docs for more information on the parameters. |
| [`run_multi_turn_rollout`](#nemo_rl-experience-rollouts-run_multi_turn_rollout) | Runs a multi-turn rollout loop, interacting with the environment. |
| [`run_sample_multi_turn_rollout`](#nemo_rl-experience-rollouts-run_sample_multi_turn_rollout) | Run a multi-turn rollout for a single sample. |

### Data

[`TokenizerType`](#nemo_rl-experience-rollouts-TokenizerType)

### API

<Anchor id="nemo_rl-experience-rollouts-AsyncNemoGymRolloutResult">

<CodeBlock links={{"nemo_rl.distributed.batched_data_dict.BatchedDataDict":"/nemo-rl/nemo_rl/distributed/batched_data_dict#nemo_rl-distributed-batched_data_dict-BatchedDataDict","nemo_rl.data.interfaces.DatumSpec":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-DatumSpec"}} showLineNumbers={false} wordWrap={true}>

```python
class nemo_rl.experience.rollouts.AsyncNemoGymRolloutResult(
    input_ids: torch.Tensor,
    final_batch: nemo_rl.distributed.batched_data_dict.BatchedDataDict[nemo_rl.data.interfaces.DatumSpec],
    rollout_metrics: dict[str, typing.Any]
)
```

</CodeBlock>
</Anchor>

<Indent>

<Badge>Dataclass</Badge>

<ParamField path="final_batch" type="BatchedDataDict[DatumSpec]">
</ParamField>

<ParamField path="input_ids" type="Tensor">
</ParamField>

<ParamField path="rollout_metrics" type="dict[str, Any]">
</ParamField>
</Indent>

<Anchor id="nemo_rl-experience-rollouts-_calculate_single_metric">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.experience.rollouts._calculate_single_metric(
    values: list[float],
    batch_size: int,
    key_name: str
) -> dict
```

</CodeBlock>
</Anchor>

<Indent>


</Indent>

<Anchor id="nemo_rl-experience-rollouts-async_generate_response_for_sample_turn">

<CodeBlock links={{"nemo_rl.models.generation.interfaces.GenerationInterface":"/nemo-rl/nemo_rl/models/generation/interfaces#nemo_rl-models-generation-interfaces-GenerationInterface","nemo_rl.experience.rollouts.TokenizerType":"#nemo_rl-experience-rollouts-TokenizerType"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.experience.rollouts.async_generate_response_for_sample_turn(
    policy_generation: nemo_rl.models.generation.interfaces.GenerationInterface,
    sample_message_log: list[dict],
    sample_stop_strings: list[str] | None,
    tokenizer: nemo_rl.experience.rollouts.TokenizerType,
    max_seq_len: int,
    greedy: bool = False
) -> tuple[list[dict], torch.Tensor, torch.Tensor, dict[str, float]]
```

</CodeBlock>
</Anchor>

<Indent>

<Badge>async</Badge>

Generate a response for a single sample's turn using async generation.

**Parameters:**

<ParamField path="policy_generation" type="GenerationInterface">
The generation interface to use
</ParamField>

<ParamField path="sample_message_log" type="list[dict]">
Message log for a single sample
</ParamField>

<ParamField path="sample_stop_strings" type="list[str] | None">
Stop strings for this sample
</ParamField>

<ParamField path="tokenizer" type="TokenizerType">
Tokenizer to use
</ParamField>

<ParamField path="max_seq_len" type="int">
Maximum sequence length
</ParamField>

<ParamField path="greedy" type="bool" default="False">
Whether to use greedy decoding
</ParamField>

**Returns:** `tuple[list[dict], torch.Tensor, torch.Tensor, dict[str, float]]`

Tuple of (updated_message_log, generated_tokens, input_lengths, generation_metrics)


</Indent>

<Anchor id="nemo_rl-experience-rollouts-calculate_rewards">

<CodeBlock links={{"nemo_rl.distributed.batched_data_dict.BatchedDataDict":"/nemo-rl/nemo_rl/distributed/batched_data_dict#nemo_rl-distributed-batched_data_dict-BatchedDataDict","nemo_rl.data.interfaces.DatumSpec":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-DatumSpec","nemo_rl.environments.interfaces.EnvironmentInterface":"/nemo-rl/nemo_rl/environments/interfaces#nemo_rl-environments-interfaces-EnvironmentInterface","nemo_rl.environments.interfaces.EnvironmentReturn":"/nemo-rl/nemo_rl/environments/interfaces#nemo_rl-environments-interfaces-EnvironmentReturn"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.experience.rollouts.calculate_rewards(
    batch: nemo_rl.distributed.batched_data_dict.BatchedDataDict[nemo_rl.data.interfaces.DatumSpec],
    task_to_env: dict[str, nemo_rl.environments.interfaces.EnvironmentInterface]
) -> nemo_rl.environments.interfaces.EnvironmentReturn
```

</CodeBlock>
</Anchor>

<Indent>

Calculate rewards for generated responses and get environment feedback.

**Parameters:**

<ParamField path="batch" type="BatchedDataDict[DatumSpec]">
Batch containing message_log (LLMMessageLogType) with generated responses
</ParamField>

<ParamField path="task_to_env" type="dict[str, EnvironmentInterface]">
Dictionary mapping task names to their corresponding environments
</ParamField>

**Returns:** `EnvironmentReturn`

EnvironmentReturn namedtuple containing:
- observations: List of observations from the environment for the next turn.
- metadata: List of extracted metadata from the environment.
- next_stop_strings: List of stop strings for the next generation step.
- rewards: Tensor of rewards for the last turn.
- terminateds: Tensor of booleans indicating if an episode ended naturally.


</Indent>

<Anchor id="nemo_rl-experience-rollouts-generate_responses">

<CodeBlock links={{"nemo_rl.models.generation.interfaces.GenerationInterface":"/nemo-rl/nemo_rl/models/generation/interfaces#nemo_rl-models-generation-interfaces-GenerationInterface","nemo_rl.distributed.batched_data_dict.BatchedDataDict":"/nemo-rl/nemo_rl/distributed/batched_data_dict#nemo_rl-distributed-batched_data_dict-BatchedDataDict","nemo_rl.models.generation.interfaces.GenerationDatumSpec":"/nemo-rl/nemo_rl/models/generation/interfaces#nemo_rl-models-generation-interfaces-GenerationDatumSpec","nemo_rl.data.interfaces.DatumSpec":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-DatumSpec","nemo_rl.experience.rollouts.TokenizerType":"#nemo_rl-experience-rollouts-TokenizerType"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.experience.rollouts.generate_responses(
    policy_generation: nemo_rl.models.generation.interfaces.GenerationInterface,
    generation_input_data: nemo_rl.distributed.batched_data_dict.BatchedDataDict[nemo_rl.models.generation.interfaces.GenerationDatumSpec],
    batch: nemo_rl.distributed.batched_data_dict.BatchedDataDict[nemo_rl.data.interfaces.DatumSpec],
    tokenizer: nemo_rl.experience.rollouts.TokenizerType,
    input_lengths: torch.Tensor,
    include_logprobs: bool = True,
    greedy: bool = False
) -> tuple[nemo_rl.distributed.batched_data_dict.BatchedDataDict[nemo_rl.data.interfaces.DatumSpec], list[torch.Tensor], dict[str, float | int]]
```

</CodeBlock>
</Anchor>

<Indent>

Generate responses from policy using synchronous generation.


</Indent>

<Anchor id="nemo_rl-experience-rollouts-generate_responses_async">

<CodeBlock links={{"nemo_rl.models.generation.interfaces.GenerationInterface":"/nemo-rl/nemo_rl/models/generation/interfaces#nemo_rl-models-generation-interfaces-GenerationInterface","nemo_rl.distributed.batched_data_dict.BatchedDataDict":"/nemo-rl/nemo_rl/distributed/batched_data_dict#nemo_rl-distributed-batched_data_dict-BatchedDataDict","nemo_rl.models.generation.interfaces.GenerationDatumSpec":"/nemo-rl/nemo_rl/models/generation/interfaces#nemo_rl-models-generation-interfaces-GenerationDatumSpec","nemo_rl.data.interfaces.DatumSpec":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-DatumSpec","nemo_rl.experience.rollouts.TokenizerType":"#nemo_rl-experience-rollouts-TokenizerType"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.experience.rollouts.generate_responses_async(
    policy_generation: nemo_rl.models.generation.interfaces.GenerationInterface,
    generation_input_data: nemo_rl.distributed.batched_data_dict.BatchedDataDict[nemo_rl.models.generation.interfaces.GenerationDatumSpec],
    batch: nemo_rl.distributed.batched_data_dict.BatchedDataDict[nemo_rl.data.interfaces.DatumSpec],
    tokenizer: nemo_rl.experience.rollouts.TokenizerType,
    input_lengths: torch.Tensor,
    include_logprobs: bool = True,
    greedy: bool = False
) -> tuple[nemo_rl.distributed.batched_data_dict.BatchedDataDict[nemo_rl.data.interfaces.DatumSpec], list[torch.Tensor], dict[str, float | int]]
```

</CodeBlock>
</Anchor>

<Indent>

<Badge>async</Badge>

Async version of generate_responses that properly calls generate_async.


</Indent>

<Anchor id="nemo_rl-experience-rollouts-run_async_multi_turn_rollout">

<CodeBlock links={{"nemo_rl.models.generation.interfaces.GenerationInterface":"/nemo-rl/nemo_rl/models/generation/interfaces#nemo_rl-models-generation-interfaces-GenerationInterface","nemo_rl.distributed.batched_data_dict.BatchedDataDict":"/nemo-rl/nemo_rl/distributed/batched_data_dict#nemo_rl-distributed-batched_data_dict-BatchedDataDict","nemo_rl.data.interfaces.DatumSpec":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-DatumSpec","nemo_rl.experience.rollouts.TokenizerType":"#nemo_rl-experience-rollouts-TokenizerType","nemo_rl.environments.interfaces.EnvironmentInterface":"/nemo-rl/nemo_rl/environments/interfaces#nemo_rl-environments-interfaces-EnvironmentInterface"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.experience.rollouts.run_async_multi_turn_rollout(
    policy_generation: nemo_rl.models.generation.interfaces.GenerationInterface,
    input_batch: nemo_rl.distributed.batched_data_dict.BatchedDataDict[nemo_rl.data.interfaces.DatumSpec],
    tokenizer: nemo_rl.experience.rollouts.TokenizerType,
    task_to_env: dict[str, nemo_rl.environments.interfaces.EnvironmentInterface],
    max_seq_len: int,
    max_rollout_turns: int = 999999,
    greedy: bool = False
) -> tuple[nemo_rl.distributed.batched_data_dict.BatchedDataDict[nemo_rl.data.interfaces.DatumSpec], dict[str, typing.Any]]
```

</CodeBlock>
</Anchor>

<Indent>

Run multi-turn rollouts with sample-level processing.

Each sample in the batch proceeds through its interaction independently.
Async generation is used internally when available but the function is synchronous.

**Parameters:**

<ParamField path="policy_generation" type="GenerationInterface">
The generation interface (policy)
</ParamField>

<ParamField path="input_batch" type="BatchedDataDict[DatumSpec]">
The starting batch containing initial message logs
</ParamField>

<ParamField path="tokenizer" type="TokenizerType">
The tokenizer
</ParamField>

<ParamField path="task_to_env" type="dict[str, EnvironmentInterface]">
Dictionary mapping task names to environment instances
</ParamField>

<ParamField path="max_seq_len" type="int">
Maximum sequence length allowed
</ParamField>

<ParamField path="max_rollout_turns" type="int" default="999999">
Maximum number of agent-environment interaction turns
</ParamField>

<ParamField path="greedy" type="bool" default="False">
Whether to use greedy decoding
</ParamField>

**Returns:** `tuple[BatchedDataDict[DatumSpec], dict[str, Any]]`

Tuple containing:
- BatchedDataDict with the full interaction history and accumulated rewards
- Dictionary of rollout metrics


</Indent>

<Anchor id="nemo_rl-experience-rollouts-run_async_nemo_gym_rollout">

<CodeBlock links={{"nemo_rl.models.generation.interfaces.GenerationInterface":"/nemo-rl/nemo_rl/models/generation/interfaces#nemo_rl-models-generation-interfaces-GenerationInterface","nemo_rl.distributed.batched_data_dict.BatchedDataDict":"/nemo-rl/nemo_rl/distributed/batched_data_dict#nemo_rl-distributed-batched_data_dict-BatchedDataDict","nemo_rl.data.interfaces.DatumSpec":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-DatumSpec","nemo_rl.experience.rollouts.TokenizerType":"#nemo_rl-experience-rollouts-TokenizerType","nemo_rl.environments.interfaces.EnvironmentInterface":"/nemo-rl/nemo_rl/environments/interfaces#nemo_rl-environments-interfaces-EnvironmentInterface","nemo_rl.models.generation.interfaces.GenerationConfig":"/nemo-rl/nemo_rl/models/generation/interfaces#nemo_rl-models-generation-interfaces-GenerationConfig","nemo_rl.experience.rollouts.AsyncNemoGymRolloutResult":"#nemo_rl-experience-rollouts-AsyncNemoGymRolloutResult"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.experience.rollouts.run_async_nemo_gym_rollout(
    policy_generation: nemo_rl.models.generation.interfaces.GenerationInterface,
    input_batch: nemo_rl.distributed.batched_data_dict.BatchedDataDict[nemo_rl.data.interfaces.DatumSpec],
    tokenizer: nemo_rl.experience.rollouts.TokenizerType,
    task_to_env: dict[str, nemo_rl.environments.interfaces.EnvironmentInterface],
    generation_config: nemo_rl.models.generation.interfaces.GenerationConfig,
    max_seq_len: typing.Optional[int] = None,
    max_rollout_turns: typing.Optional[int] = None,
    greedy: bool = False
) -> nemo_rl.experience.rollouts.AsyncNemoGymRolloutResult
```

</CodeBlock>
</Anchor>

<Indent>

Run multi-turn rollouts with NeMo-Gym. Please refer to the `run_async_multi_turn_rollout` docs for more information on the parameters.


</Indent>

<Anchor id="nemo_rl-experience-rollouts-run_multi_turn_rollout">

<CodeBlock links={{"nemo_rl.models.generation.interfaces.GenerationInterface":"/nemo-rl/nemo_rl/models/generation/interfaces#nemo_rl-models-generation-interfaces-GenerationInterface","nemo_rl.distributed.batched_data_dict.BatchedDataDict":"/nemo-rl/nemo_rl/distributed/batched_data_dict#nemo_rl-distributed-batched_data_dict-BatchedDataDict","nemo_rl.data.interfaces.DatumSpec":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-DatumSpec","nemo_rl.experience.rollouts.TokenizerType":"#nemo_rl-experience-rollouts-TokenizerType","nemo_rl.environments.interfaces.EnvironmentInterface":"/nemo-rl/nemo_rl/environments/interfaces#nemo_rl-environments-interfaces-EnvironmentInterface"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.experience.rollouts.run_multi_turn_rollout(
    policy_generation: nemo_rl.models.generation.interfaces.GenerationInterface,
    input_batch: nemo_rl.distributed.batched_data_dict.BatchedDataDict[nemo_rl.data.interfaces.DatumSpec],
    tokenizer: nemo_rl.experience.rollouts.TokenizerType,
    task_to_env: dict[str, nemo_rl.environments.interfaces.EnvironmentInterface],
    max_seq_len: int,
    max_rollout_turns: int = 999999,
    greedy: bool = False
) -> tuple[nemo_rl.distributed.batched_data_dict.BatchedDataDict[nemo_rl.data.interfaces.DatumSpec], dict[str, typing.Any]]
```

</CodeBlock>
</Anchor>

<Indent>

Runs a multi-turn rollout loop, interacting with the environment.

**Parameters:**

<ParamField path="policy_generation" type="GenerationInterface">
The generation interface (policy).
</ParamField>

<ParamField path="input_batch" type="BatchedDataDict[DatumSpec]">
The starting batch containing initial message logs.
</ParamField>

<ParamField path="tokenizer" type="TokenizerType">
The tokenizer.
</ParamField>

<ParamField path="task_to_env" type="dict[str, EnvironmentInterface]">
Dictionary mapping task names to environment instances.
</ParamField>

<ParamField path="max_rollout_turns" type="int" default="999999">
Maximum number of agent-environment interaction turns.
</ParamField>

<ParamField path="max_seq_len" type="int">
Maximum sequence length allowed.
</ParamField>

<ParamField path="greedy" type="bool" default="False">
Whether to use greedy decoding.
</ParamField>

**Returns:** `tuple[BatchedDataDict[DatumSpec], dict[str, Any]]`

Tuple containing:
- BatchedDataDict with the full interaction history and accumulated rewards
- Dictionary of rollout metrics


</Indent>

<Anchor id="nemo_rl-experience-rollouts-run_sample_multi_turn_rollout">

<CodeBlock links={{"nemo_rl.models.generation.interfaces.GenerationInterface":"/nemo-rl/nemo_rl/models/generation/interfaces#nemo_rl-models-generation-interfaces-GenerationInterface","nemo_rl.experience.rollouts.TokenizerType":"#nemo_rl-experience-rollouts-TokenizerType","nemo_rl.environments.interfaces.EnvironmentInterface":"/nemo-rl/nemo_rl/environments/interfaces#nemo_rl-environments-interfaces-EnvironmentInterface"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.experience.rollouts.run_sample_multi_turn_rollout(
    sample_idx: int,
    initial_sample_state: dict,
    policy_generation: nemo_rl.models.generation.interfaces.GenerationInterface,
    tokenizer: nemo_rl.experience.rollouts.TokenizerType,
    task_to_env: dict[str, nemo_rl.environments.interfaces.EnvironmentInterface],
    max_seq_len: int,
    max_rollout_turns: int = 999999,
    greedy: bool = False
) -> tuple[dict, dict[str, typing.Any]]
```

</CodeBlock>
</Anchor>

<Indent>

<Badge>async</Badge>

Run a multi-turn rollout for a single sample.

This function manages the complete lifecycle of one sample's interaction.
Async generation is used internally when available.

**Parameters:**

<ParamField path="sample_idx" type="int">
Index of this sample in the original batch
</ParamField>

<ParamField path="initial_sample_state" type="dict">
Initial state containing message_log, extra_env_info, etc.
</ParamField>

<ParamField path="policy_generation" type="GenerationInterface">
The generation interface
</ParamField>

<ParamField path="tokenizer" type="TokenizerType">
Tokenizer to use
</ParamField>

<ParamField path="task_to_env" type="dict[str, EnvironmentInterface]">
Environment mapping
</ParamField>

<ParamField path="max_seq_len" type="int">
Maximum sequence length
</ParamField>

<ParamField path="max_rollout_turns" type="int" default="999999">
Maximum number of turns
</ParamField>

<ParamField path="greedy" type="bool" default="False">
Whether to use greedy decoding
</ParamField>

**Returns:** `tuple[dict, dict[str, Any]]`

Tuple of (final_sample_state, sample_metrics)


</Indent>

<Anchor id="nemo_rl-experience-rollouts-TokenizerType">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.experience.rollouts.TokenizerType = PreTrainedTokenizerBase
```

</CodeBlock>
</Anchor>

