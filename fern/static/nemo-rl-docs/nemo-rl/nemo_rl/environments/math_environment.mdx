---
layout: overview
slug: nemo-rl/nemo_rl/environments/math_environment
title: nemo_rl.environments.math_environment
---

## Module Contents

### Classes

| Name | Description |
|------|-------------|
| [`EnglishMultichoiceVerifyWorker`](#nemo_rl-environments-math_environment-EnglishMultichoiceVerifyWorker) | - |
| [`HFVerifyWorker`](#nemo_rl-environments-math_environment-HFVerifyWorker) | - |
| [`MathEnvConfig`](#nemo_rl-environments-math_environment-MathEnvConfig) | - |
| [`MathEnvironment`](#nemo_rl-environments-math_environment-MathEnvironment) | - |
| [`MathEnvironmentMetadata`](#nemo_rl-environments-math_environment-MathEnvironmentMetadata) | - |
| [`MultilingualMultichoiceVerifyWorker`](#nemo_rl-environments-math_environment-MultilingualMultichoiceVerifyWorker) | - |

### Functions

| Name | Description |
|------|-------------|
| [`_mute_output`](#nemo_rl-environments-math_environment-_mute_output) | - |

### API

<Anchor id="nemo_rl-environments-math_environment-EnglishMultichoiceVerifyWorker">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
class nemo_rl.environments.math_environment.EnglishMultichoiceVerifyWorker()
```

</CodeBlock>
</Anchor>

<Indent>

<Anchor id="nemo_rl-environments-math_environment-EnglishMultichoiceVerifyWorker-verify">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.environments.math_environment.EnglishMultichoiceVerifyWorker.verify(
    pred_responses: list[str],
    ground_truths: list[str],
    return_extracted_answer: bool = False,
    kwargs = {}
) -> typing.Union[list[float], tuple[list[float], list[str | None]]]
```

</CodeBlock>
</Anchor>

<Indent>

Verify the correctness of the predicted responses against the ground truth.

**Parameters:**

<ParamField path="pred_responses" type="list[str]">
list[str]. The predicted responses from the LLM.
</ParamField>

<ParamField path="ground_truths" type="list[str]">
list[str]. The ground truth responses.
</ParamField>

**Returns:** `Union[list[float], tuple[list[float], list[str | None]]]`

Union[list[float], tuple[list[float], list[str | None]]].


</Indent>
</Indent>

<Anchor id="nemo_rl-environments-math_environment-HFVerifyWorker">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
class nemo_rl.environments.math_environment.HFVerifyWorker()
```

</CodeBlock>
</Anchor>

<Indent>

<ParamField path="verify_func">
</ParamField>
<Anchor id="nemo_rl-environments-math_environment-HFVerifyWorker-verify">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.environments.math_environment.HFVerifyWorker.verify(
    pred_responses: list[str],
    ground_truths: list[str],
    return_extracted_answer: bool = False,
    kwargs = {}
) -> typing.Union[list[float], tuple[list[float], list[str | None]]]
```

</CodeBlock>
</Anchor>

<Indent>

Verify the correctness of the predicted responses against the ground truth.

**Parameters:**

<ParamField path="pred_responses" type="list[str]">
list[str]. The predicted responses from the LLM.
</ParamField>

<ParamField path="ground_truths" type="list[str]">
list[str]. The ground truth responses.
</ParamField>

**Returns:** `Union[list[float], tuple[list[float], list[str | None]]]`

Union[list[float], tuple[list[float], list[str | None]]].


</Indent>
</Indent>

<Anchor id="nemo_rl-environments-math_environment-MathEnvConfig">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
class nemo_rl.environments.math_environment.MathEnvConfig
```

</CodeBlock>
</Anchor>

<Indent>

**Bases:** `typing.TypedDict`

<ParamField path="math_verify_impl" type="NotRequired[str | None]">

</ParamField>

<ParamField path="num_workers" type="int">

</ParamField>

<ParamField path="stop_strings" type="NotRequired[list[str] | None]">

</ParamField>

<ParamField path="verifier_type" type="NotRequired[str | None]">

</ParamField>

</Indent>

<Anchor id="nemo_rl-environments-math_environment-MathEnvironment">

<CodeBlock links={{"nemo_rl.environments.math_environment.MathEnvConfig":"#nemo_rl-environments-math_environment-MathEnvConfig"}} showLineNumbers={false} wordWrap={true}>

```python
class nemo_rl.environments.math_environment.MathEnvironment(
    cfg: nemo_rl.environments.math_environment.MathEnvConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

**Bases:** [EnvironmentInterface[MathEnvironmentMetadata]](/nemo-rl/nemo_rl/environments/interfaces#nemo_rl-environments-interfaces-EnvironmentInterface)

<ParamField path="num_workers" type="= cfg['num_workers']">
</ParamField>

<ParamField path="workers">
</ParamField>
<Anchor id="nemo_rl-environments-math_environment-MathEnvironment-global_post_process_and_metrics">

<CodeBlock links={{"nemo_rl.distributed.batched_data_dict.BatchedDataDict":"/nemo-rl/nemo_rl/distributed/batched_data_dict#nemo_rl-distributed-batched_data_dict-BatchedDataDict"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.environments.math_environment.MathEnvironment.global_post_process_and_metrics(
    batch: nemo_rl.distributed.batched_data_dict.BatchedDataDict[typing.Any]
) -> tuple[nemo_rl.distributed.batched_data_dict.BatchedDataDict[typing.Any], dict[str, float | int]]
```

</CodeBlock>
</Anchor>

<Indent>

Computes metrics for this environment given a global rollout batch.

Every rank will run this function, so you're free to use distributed
calculations if you'd prefer for heavy metrics.


</Indent>
<Anchor id="nemo_rl-environments-math_environment-MathEnvironment-shutdown">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.environments.math_environment.MathEnvironment.shutdown() -> None
```

</CodeBlock>
</Anchor>

<Indent>


</Indent>
<Anchor id="nemo_rl-environments-math_environment-MathEnvironment-step">

<CodeBlock links={{"nemo_rl.data.interfaces.LLMMessageLogType":"/nemo-rl/nemo_rl/data/interfaces#nemo_rl-data-interfaces-LLMMessageLogType","nemo_rl.environments.math_environment.MathEnvironmentMetadata":"#nemo_rl-environments-math_environment-MathEnvironmentMetadata","nemo_rl.environments.interfaces.EnvironmentReturn":"/nemo-rl/nemo_rl/environments/interfaces#nemo_rl-environments-interfaces-EnvironmentReturn"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.environments.math_environment.MathEnvironment.step(
    message_log_batch: list[nemo_rl.data.interfaces.LLMMessageLogType],
    metadata: list[nemo_rl.environments.math_environment.MathEnvironmentMetadata],
    return_extracted_answer: bool = False
) -> nemo_rl.environments.interfaces.EnvironmentReturn[nemo_rl.environments.math_environment.MathEnvironmentMetadata]
```

</CodeBlock>
</Anchor>

<Indent>

Runs a step in the math environment.

**Parameters:**

<ParamField path="message_log">
list[list[dict[str, str]]]. A batch of OpenAI-API-like message logs that represent interactions with the LLM.
</ParamField>

<ParamField path="metadata" type="list[MathEnvironmentMetadata]">
list[MathEnvironmentMetadata]. The grader will use the 'ground_truth' key to evaluate correctness. The extracted answer will be stored to caculate cons@k.
</ParamField>

**Returns:** `EnvironmentReturn[MathEnvironmentMetadata]`

A tuple containing:
- list[dict[str, str]]: Observations/responses batch
- list[dict]: Updated metadata
- list[str]: Next stop strings for the next turn
- Tensor: Rewards tensor
- Tensor: Done flags tensor


</Indent>
</Indent>

<Anchor id="nemo_rl-environments-math_environment-MathEnvironmentMetadata">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
class nemo_rl.environments.math_environment.MathEnvironmentMetadata
```

</CodeBlock>
</Anchor>

<Indent>

**Bases:** `typing.TypedDict`

<ParamField path="extracted_answer" type="str | None">

</ParamField>

<ParamField path="ground_truth" type="str">

</ParamField>

</Indent>

<Anchor id="nemo_rl-environments-math_environment-MultilingualMultichoiceVerifyWorker">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
class nemo_rl.environments.math_environment.MultilingualMultichoiceVerifyWorker()
```

</CodeBlock>
</Anchor>

<Indent>

<Anchor id="nemo_rl-environments-math_environment-MultilingualMultichoiceVerifyWorker-verify">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.environments.math_environment.MultilingualMultichoiceVerifyWorker.verify(
    pred_responses: list[str],
    ground_truths: list[str],
    return_extracted_answer: bool = False,
    kwargs = {}
) -> typing.Union[list[float], tuple[list[float], list[str | None]]]
```

</CodeBlock>
</Anchor>

<Indent>

Verify the correctness of the predicted responses against the ground truth.

**Parameters:**

<ParamField path="pred_responses" type="list[str]">
list[str]. The predicted responses from the LLM.
</ParamField>

<ParamField path="ground_truths" type="list[str]">
list[str]. The ground truth responses.
</ParamField>

**Returns:** `Union[list[float], tuple[list[float], list[str | None]]]`

Union[list[float], tuple[list[float], list[str | None]]].


</Indent>
</Indent>

<Anchor id="nemo_rl-environments-math_environment-_mute_output">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.environments.math_environment._mute_output()
```

</CodeBlock>
</Anchor>

<Indent>


</Indent>
