---
layout: overview
slug: nemo-rl/nemo_rl/utils/flops_formulas
title: nemo_rl.utils.flops_formulas
---

## Module Contents

### Classes

| Name | Description |
|------|-------------|
| [`FLOPSConfig`](#nemo_rl-utils-flops_formulas-FLOPSConfig) | Contains the model hparams needed for FLOPS computations. |

### Functions

| Name | Description |
|------|-------------|
| [`_hybrid_model_flops`](#nemo_rl-utils-flops_formulas-_hybrid_model_flops) | Model FLOPs for hybrid model. |
| [`_mamba_layer_flops`](#nemo_rl-utils-flops_formulas-_mamba_layer_flops) | Model FLOPs for Mamba layer. We ignore part of the flops of scan because the chunk size is not known from model config. |
| [`_mlp_layer_flops`](#nemo_rl-utils-flops_formulas-_mlp_layer_flops) | Model FLOPs for MLP layer. |
| [`_non_mla_attn_layer_flops`](#nemo_rl-utils-flops_formulas-_non_mla_attn_layer_flops) | Model FLOPs for attention layer. |
| [`bert`](#nemo_rl-utils-flops_formulas-bert) | Model FLOPs for BERT family. |
| [`deepseekv3`](#nemo_rl-utils-flops_formulas-deepseekv3) | Model FLOPs for DeepSeek V3. |
| [`flux`](#nemo_rl-utils-flops_formulas-flux) | Model FLOPs for FLUX. |
| [`gpt3`](#nemo_rl-utils-flops_formulas-gpt3) | Model FLOPs for GPT3 family. |
| [`llama`](#nemo_rl-utils-flops_formulas-llama) | Model FLOPs for llama3 family. |
| [`mixtral`](#nemo_rl-utils-flops_formulas-mixtral) | Model FLOPs for mixtral family. |
| [`nemotron`](#nemo_rl-utils-flops_formulas-nemotron) | Model FLOPs for nemotron family. |
| [`nemotronh`](#nemo_rl-utils-flops_formulas-nemotronh) | Model FLOPs for NemotronH. |
| [`qwen2`](#nemo_rl-utils-flops_formulas-qwen2) | Model FLOPs for Qwen2 family. |
| [`qwen3`](#nemo_rl-utils-flops_formulas-qwen3) | Model FLOPs for Qwen3 family. |
| [`transformer`](#nemo_rl-utils-flops_formulas-transformer) | Calculate FLOPs for a standard Transformer model. |

### API

<Anchor id="nemo_rl-utils-flops_formulas-FLOPSConfig">

<CodeBlock showLineNumbers={false} wordWrap={true}>

```python
class nemo_rl.utils.flops_formulas.FLOPSConfig(
    gbs: int,
    enc_seq_len: typing.Optional[int] = None,
    hs: typing.Optional[int] = None,
    layers: typing.Optional[int] = None,
    ffn_hs: typing.Optional[int] = None,
    attention_heads: typing.Optional[int] = None,
    moe_router_topk: typing.Optional[int] = None,
    query_groups: typing.Optional[int] = None,
    img_seq_len: typing.Optional[int] = None,
    img_h: typing.Optional[int] = None,
    img_w: typing.Optional[int] = None,
    in_channels: typing.Optional[int] = None,
    patch_dim: typing.Optional[int] = None,
    class_token_len: typing.Optional[int] = None,
    projector_type: typing.Optional[str] = None,
    inp_s: typing.Optional[int] = None,
    model_pattern: typing.Optional[str] = None,
    vocab_size: typing.Optional[int] = None,
    model_channels: typing.Optional[int] = None,
    vec_in_dim: typing.Optional[int] = None,
    q_lora_rank: typing.Optional[int] = None,
    kv_lora_rank: typing.Optional[int] = None,
    qk_head_dim: typing.Optional[int] = None,
    qk_pos_emb_head_dim: typing.Optional[int] = None,
    v_head_dim: typing.Optional[int] = None,
    moe_layer_freq: typing.Optional[typing.Union[int, typing.List[int]]] = None,
    moe_shared_expert_intermediate_size: typing.Optional[int] = None,
    moe_ffn_hidden_size: typing.Optional[int] = None,
    mtp_num_layers: typing.Optional[int] = None,
    causal_self_attn: typing.Optional[bool] = None,
    is_hybrid_model: bool = False,
    hybrid_override_pattern: typing.Optional[str] = None,
    mamba_state_dim: typing.Optional[int] = None,
    mamba_head_dim: typing.Optional[int] = None,
    mamba_num_groups: typing.Optional[int] = None,
    mamba_num_heads: typing.Optional[int] = None
)
```

</CodeBlock>
</Anchor>

<Indent>

<Badge>Dataclass</Badge>

Contains the model hparams needed for FLOPS computations.


<ParamField path="attention_heads" type="Optional[int] = None">
</ParamField>

<ParamField path="causal_self_attn" type="Optional[bool] = None">
</ParamField>

<ParamField path="class_token_len" type="Optional[int] = None">
</ParamField>

<ParamField path="enc_seq_len" type="Optional[int] = None">
</ParamField>

<ParamField path="ffn_hs" type="Optional[int] = None">
</ParamField>

<ParamField path="gbs" type="int">
</ParamField>

<ParamField path="hs" type="Optional[int] = None">
</ParamField>

<ParamField path="hybrid_override_pattern" type="Optional[str] = None">
</ParamField>

<ParamField path="img_h" type="Optional[int] = None">
</ParamField>

<ParamField path="img_seq_len" type="Optional[int] = None">
</ParamField>

<ParamField path="img_w" type="Optional[int] = None">
</ParamField>

<ParamField path="in_channels" type="Optional[int] = None">
</ParamField>

<ParamField path="inp_s" type="Optional[int] = None">
</ParamField>

<ParamField path="is_hybrid_model" type="bool = False">
</ParamField>

<ParamField path="kv_lora_rank" type="Optional[int] = None">
</ParamField>

<ParamField path="layers" type="Optional[int] = None">
</ParamField>

<ParamField path="mamba_head_dim" type="Optional[int] = None">
</ParamField>

<ParamField path="mamba_num_groups" type="Optional[int] = None">
</ParamField>

<ParamField path="mamba_num_heads" type="Optional[int] = None">
</ParamField>

<ParamField path="mamba_state_dim" type="Optional[int] = None">
</ParamField>

<ParamField path="model_channels" type="Optional[int] = None">
</ParamField>

<ParamField path="model_pattern" type="Optional[str] = None">
</ParamField>

<ParamField path="moe_ffn_hidden_size" type="Optional[int] = None">
</ParamField>

<ParamField path="moe_layer_freq" type="Optional[Union[int, List[int]]] = None">
</ParamField>

<ParamField path="moe_router_topk" type="Optional[int] = None">
</ParamField>

<ParamField path="moe_shared_expert_intermediate_size" type="Optional[int] = None">
</ParamField>

<ParamField path="mtp_num_layers" type="Optional[int] = None">
</ParamField>

<ParamField path="patch_dim" type="Optional[int] = None">
</ParamField>

<ParamField path="projector_type" type="Optional[str] = None">
</ParamField>

<ParamField path="q_lora_rank" type="Optional[int] = None">
</ParamField>

<ParamField path="qk_head_dim" type="Optional[int] = None">
</ParamField>

<ParamField path="qk_pos_emb_head_dim" type="Optional[int] = None">
</ParamField>

<ParamField path="query_groups" type="Optional[int] = None">
</ParamField>

<ParamField path="v_head_dim" type="Optional[int] = None">
</ParamField>

<ParamField path="vec_in_dim" type="Optional[int] = None">
</ParamField>

<ParamField path="vocab_size" type="Optional[int] = None">
</ParamField>
</Indent>

<Anchor id="nemo_rl-utils-flops_formulas-_hybrid_model_flops">

<CodeBlock links={{"nemo_rl.utils.flops_formulas.FLOPSConfig":"#nemo_rl-utils-flops_formulas-FLOPSConfig"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.utils.flops_formulas._hybrid_model_flops(
    config: nemo_rl.utils.flops_formulas.FLOPSConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

Model FLOPs for hybrid model.


</Indent>

<Anchor id="nemo_rl-utils-flops_formulas-_mamba_layer_flops">

<CodeBlock links={{"nemo_rl.utils.flops_formulas.FLOPSConfig":"#nemo_rl-utils-flops_formulas-FLOPSConfig"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.utils.flops_formulas._mamba_layer_flops(
    config: nemo_rl.utils.flops_formulas.FLOPSConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

Model FLOPs for Mamba layer. We ignore part of the flops of scan because the chunk size is not known from model config.


</Indent>

<Anchor id="nemo_rl-utils-flops_formulas-_mlp_layer_flops">

<CodeBlock links={{"nemo_rl.utils.flops_formulas.FLOPSConfig":"#nemo_rl-utils-flops_formulas-FLOPSConfig"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.utils.flops_formulas._mlp_layer_flops(
    config: nemo_rl.utils.flops_formulas.FLOPSConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

Model FLOPs for MLP layer.


</Indent>

<Anchor id="nemo_rl-utils-flops_formulas-_non_mla_attn_layer_flops">

<CodeBlock links={{"nemo_rl.utils.flops_formulas.FLOPSConfig":"#nemo_rl-utils-flops_formulas-FLOPSConfig"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.utils.flops_formulas._non_mla_attn_layer_flops(
    config: nemo_rl.utils.flops_formulas.FLOPSConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

Model FLOPs for attention layer.


</Indent>

<Anchor id="nemo_rl-utils-flops_formulas-bert">

<CodeBlock links={{"nemo_rl.utils.flops_formulas.FLOPSConfig":"#nemo_rl-utils-flops_formulas-FLOPSConfig"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.utils.flops_formulas.bert(
    config: nemo_rl.utils.flops_formulas.FLOPSConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

Model FLOPs for BERT family.


</Indent>

<Anchor id="nemo_rl-utils-flops_formulas-deepseekv3">

<CodeBlock links={{"nemo_rl.utils.flops_formulas.FLOPSConfig":"#nemo_rl-utils-flops_formulas-FLOPSConfig"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.utils.flops_formulas.deepseekv3(
    config: nemo_rl.utils.flops_formulas.FLOPSConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

Model FLOPs for DeepSeek V3.


</Indent>

<Anchor id="nemo_rl-utils-flops_formulas-flux">

<CodeBlock links={{"nemo_rl.utils.flops_formulas.FLOPSConfig":"#nemo_rl-utils-flops_formulas-FLOPSConfig"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.utils.flops_formulas.flux(
    config: nemo_rl.utils.flops_formulas.FLOPSConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

Model FLOPs for FLUX.


</Indent>

<Anchor id="nemo_rl-utils-flops_formulas-gpt3">

<CodeBlock links={{"nemo_rl.utils.flops_formulas.FLOPSConfig":"#nemo_rl-utils-flops_formulas-FLOPSConfig"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.utils.flops_formulas.gpt3(
    config: nemo_rl.utils.flops_formulas.FLOPSConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

Model FLOPs for GPT3 family.


</Indent>

<Anchor id="nemo_rl-utils-flops_formulas-llama">

<CodeBlock links={{"nemo_rl.utils.flops_formulas.FLOPSConfig":"#nemo_rl-utils-flops_formulas-FLOPSConfig"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.utils.flops_formulas.llama(
    config: nemo_rl.utils.flops_formulas.FLOPSConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

Model FLOPs for llama3 family.


</Indent>

<Anchor id="nemo_rl-utils-flops_formulas-mixtral">

<CodeBlock links={{"nemo_rl.utils.flops_formulas.FLOPSConfig":"#nemo_rl-utils-flops_formulas-FLOPSConfig"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.utils.flops_formulas.mixtral(
    config: nemo_rl.utils.flops_formulas.FLOPSConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

Model FLOPs for mixtral family.


</Indent>

<Anchor id="nemo_rl-utils-flops_formulas-nemotron">

<CodeBlock links={{"nemo_rl.utils.flops_formulas.FLOPSConfig":"#nemo_rl-utils-flops_formulas-FLOPSConfig"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.utils.flops_formulas.nemotron(
    config: nemo_rl.utils.flops_formulas.FLOPSConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

Model FLOPs for nemotron family.


</Indent>

<Anchor id="nemo_rl-utils-flops_formulas-nemotronh">

<CodeBlock links={{"nemo_rl.utils.flops_formulas.FLOPSConfig":"#nemo_rl-utils-flops_formulas-FLOPSConfig"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.utils.flops_formulas.nemotronh(
    config: nemo_rl.utils.flops_formulas.FLOPSConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

Model FLOPs for NemotronH.


</Indent>

<Anchor id="nemo_rl-utils-flops_formulas-qwen2">

<CodeBlock links={{"nemo_rl.utils.flops_formulas.FLOPSConfig":"#nemo_rl-utils-flops_formulas-FLOPSConfig"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.utils.flops_formulas.qwen2(
    config: nemo_rl.utils.flops_formulas.FLOPSConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

Model FLOPs for Qwen2 family.


</Indent>

<Anchor id="nemo_rl-utils-flops_formulas-qwen3">

<CodeBlock links={{"nemo_rl.utils.flops_formulas.FLOPSConfig":"#nemo_rl-utils-flops_formulas-FLOPSConfig"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.utils.flops_formulas.qwen3(
    config: nemo_rl.utils.flops_formulas.FLOPSConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

Model FLOPs for Qwen3 family.


</Indent>

<Anchor id="nemo_rl-utils-flops_formulas-transformer">

<CodeBlock links={{"nemo_rl.utils.flops_formulas.FLOPSConfig":"#nemo_rl-utils-flops_formulas-FLOPSConfig"}} showLineNumbers={false} wordWrap={true}>

```python
nemo_rl.utils.flops_formulas.transformer(
    config: nemo_rl.utils.flops_formulas.FLOPSConfig
)
```

</CodeBlock>
</Anchor>

<Indent>

Calculate FLOPs for a standard Transformer model.

Note: This does not cover encoder-decoder models.


</Indent>
